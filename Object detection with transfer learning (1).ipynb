{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "363d31af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import PIL\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e41d6ae1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951ebdb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "detector = hub.load(module_handle).signatures['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f383b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "beach_image_path = \"C:/Users/allan/Desktop/beach_image.jfif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9455c040",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = tf.io.read_file(beach_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b45229",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = tf.image.decode_jpeg(img, channels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a04ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "converted_img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "converted_img = tf.expand_dims(converted_img, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d385b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(converted_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30439cda",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(converted_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f201609",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = detector(converted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9747144",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_intersection_over_union(rect1, rect2):\n",
    "    rect1_top_left = rect1.get_xy()\n",
    "    rect1_width = rect1.get_width()\n",
    "    rect1_height = rect1.get_height()\n",
    "    \n",
    "    rect2_top_left = rect2.get_xy()\n",
    "    rect2_width = rect2.get_width()\n",
    "    rect2_height = rect2.get_height()\n",
    "    \n",
    "    #Calculate points that's needed for the formula\n",
    "    rect1_left = rect1_top_left[0]\n",
    "    rect1_top = rect1_top_left[1]\n",
    "    rect1_right = rect1_left + rect1_width\n",
    "    rect1_bottom = rect1_top + rect1_height\n",
    "    \n",
    "    rect2_left = rect2_top_left[0]\n",
    "    rect2_top = rect2_top_left[1]\n",
    "    rect2_right = rect2_left + rect2_width\n",
    "    rect2_bottom = rect2_top + rect2_height\n",
    "    \n",
    "    x_overlap = max(0, min(rect1_right, rect2_right) - max(rect1_left, rect2_left))\n",
    "    y_overlap = max(0, min(rect1_bottom, rect2_bottom) - max(rect1_top, rect2_top))\n",
    "\n",
    "\n",
    "    intersection_area = x_overlap * y_overlap\n",
    "    rect1_area = rect1_width * rect1_height\n",
    "    rect2_area = rect2_width * rect2_height\n",
    "    combined_area = rect1_area + rect2_area\n",
    "    \n",
    "    union_area = combined_area - intersection_area\n",
    "    intersection_over_union = intersection_area/union_area\n",
    "    #print(\"Intersection area is {0} and ratio is {1}\".format(intersection_area, intersection_over_union))\n",
    "   \n",
    "    return rect1_area, rect2_area, intersection_over_union, intersection_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1f7f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def is_IoU_too_high(new_patch, list_of_patches):\n",
    "    for single_patch in list_of_patches:\n",
    "        area1, area2, intersection_over_union, intersection = get_intersection_over_union(new_patch, single_patch)\n",
    "        if intersection > 0.95:\n",
    "            return True\n",
    "        if intersection_over_union > 0.85:\n",
    "            return True\n",
    "\n",
    "def filter_list_of_patches(new_patch, list_of_patches):\n",
    "    if len(list_of_patches) == 0: #If the list is empty, just append the new patch to the list\n",
    "        list_of_patches.append(new_patch)\n",
    "        #print(\"first patch added\")\n",
    "        return list_of_patches\n",
    "    else:\n",
    "        #You have to check if any of the patches in the list have IoU over 0.85\n",
    "        if not is_IoU_too_high(new_patch, list_of_patches):\n",
    "            list_of_patches.append(new_patch)            \n",
    "    return list_of_patches\n",
    "                \n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6494af",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_all_bounding_boxes(image_path, list_of_patches): #Once I get the list of patches here, I should filter them down\n",
    "    im = PIL.Image.open(image_path)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(im)\n",
    "    \n",
    "    for patch in list_of_patches:\n",
    "        ax.add_patch(patch)\n",
    "    plt.show()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be843837",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def define_rectangles(indices_list, image_path, image, predictions_tensor):\n",
    "    #Get the image dimensions\n",
    "    height = image.shape[1]\n",
    "    width = image.shape[2]\n",
    "    \n",
    "    #Create an empty list of patches\n",
    "    list_of_patches = []\n",
    "    #Loop through the indices list to draw all bounding boxes\n",
    "    for index in indices_list:\n",
    "        #print(\"Adding index {0}\".format(index))\n",
    "        #Get the bounding box dimensions for 1 object\n",
    "        bounding_box_scaled_dimensions = predictions_tensor['detection_boxes'][index].numpy()\n",
    "        #Calculate all the coordinates needed for 1 object's bounding box\n",
    "        xCoord0 = bounding_box_scaled_dimensions[1]*width\n",
    "        yCoord0 = bounding_box_scaled_dimensions[0]*height\n",
    "        bounding_box_width = (bounding_box_scaled_dimensions[3]- bounding_box_scaled_dimensions[1])*width\n",
    "        bounding_box_height = (bounding_box_scaled_dimensions[2]- bounding_box_scaled_dimensions[0])*height\n",
    "        #Create a patch\n",
    "        rect = patches.Rectangle((xCoord0, yCoord0), bounding_box_width, bounding_box_height, linewidth = 2, edgecolor = 'r', facecolor = 'none')\n",
    "\n",
    "        #Filter the list of patches here. Instead of adding it directly, we use the filter function\n",
    "        list_of_patches = filter_list_of_patches(rect, list_of_patches)\n",
    "        pass\n",
    "    #Draw all patches\n",
    "    draw_all_bounding_boxes(image_path, list_of_patches)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07c13c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_valid_bounding_boxes(predictions_tensor):\n",
    "    #predictions['detection_scores']\n",
    "    counter = 0\n",
    "    index_list = []\n",
    "    prediction_scores_array = np.array(predictions_tensor['detection_scores'], dtype = 'float32')\n",
    "    for index, confidence in enumerate(prediction_scores_array):\n",
    "        if confidence >= 0.01:\n",
    "            counter +=1\n",
    "            #print(index)\n",
    "            index_list.append(index)\n",
    "        else:\n",
    "            break\n",
    "        pass\n",
    "    return index_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e714e0b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_valid_indices(predictions_tensor):\n",
    "    indices_list = []\n",
    "    for index, score in enumerate(predictions['detection_scores']):\n",
    "        if score > 0.4:\n",
    "            indices_list.append(index)\n",
    "        else:\n",
    "            break #Break here because the list is ordered. all future scores will be below 0.4\n",
    "        pass\n",
    "    \n",
    "    #Filter the list further \n",
    "    temp_list = indices_list\n",
    "    for index in temp_list:\n",
    "        #print(\"{1} is the index of entity {0}\".format(predictions_tensor['detection_class_entities'][index], index))\n",
    "        current_entity = np.array(predictions_tensor['detection_class_entities'], dtype = 'str')[index]\n",
    "        print(\"Current entity is {}\".format(current_entity))\n",
    "\n",
    "    return indices_list\n",
    "\n",
    "\n",
    "#define_rectangles(get_valid_indices(predictions), beach_image_path, converted_image, predictions)\n",
    "\n",
    "#draw_bounding_boxes > get_valid_indices > get_valid_bounding_boxes > draw_all_bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c7373",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def locate_objects_for_image(image_path):\n",
    "    #Prepare the image\n",
    "    \n",
    "    #Read the image\n",
    "    img = tf.io.read_file(image_path)\n",
    "    #Decode the image\n",
    "    img = tf.image.decode_jpeg(img, channels = 3)\n",
    "    #Convert to float32\n",
    "    converted_img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    #Expand dims so it is compatible with the model\n",
    "    converted_img = tf.expand_dims(converted_img, axis = 0)\n",
    "    #Draw the initial image\n",
    "    #plt.imshow(converted_img[0])\n",
    "    \n",
    "    #Object detection part starts here\n",
    "    predictions_tensor = detector(converted_img)\n",
    "\n",
    "\n",
    "    \n",
    "    indices_list = get_valid_indices(predictions_tensor)\n",
    "    \n",
    "    #indices_list = [x for x in range(5)]\n",
    "    define_rectangles(indices_list, image_path, converted_img, predictions_tensor)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e7ca8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "football_image_path = \"C:/Users/allan/OneDrive/Desktop/PES_Image.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc34235",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locate_objects_for_image(beach_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d82dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "face_image_path = \"C:/Users/allan/Desktop/face_image.jfif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae546e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "locate_objects_for_image(face_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619480dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = tf.io.read_file(face_image_path)\n",
    "#Decode the image\n",
    "img = tf.image.decode_jpeg(img, channels = 3)\n",
    "#Convert to float32\n",
    "converted_img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#Expand dims so it is compatible with the model\n",
    "converted_img = tf.expand_dims(converted_img, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf824da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "face_picture_predictions = detector(converted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdb9cef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(face_picture_predictions.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cefef22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(face_picture_predictions['detection_class_entities'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661772b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5896b78e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
